{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vQDnyBvT716"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data Toolkit"
      ],
      "metadata": {
        "id": "Om7NqFYyVyLn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. What is NumPy, and why is it widely used in Python ?\n",
        "- NumPy (Numerical Python) is an open-source library for the Python programming language, widely used for scientific computing. It provides support for large multi-dimensional arrays and matrices, along with a collection of high-level mathematical functions to operate on these arrays. Here's why it's so widely used:\n",
        "\n",
        "- a . Efficient Array Operations: NumPy allows for the creation and manipulation of large arrays with high performance. It is highly optimized for numerical operations and offers significant speed improvements over traditional Python lists.\n",
        "\n",
        "- b . Multi-dimensional Arrays: NumPy introduces the ndarray object, which is a powerful N-dimensional array. It allows you to perform mathematical operations on entire arrays of data, without the need for explicit loops, which enhances both code readability and performance.\n",
        "\n",
        "- c . Vectorization: NumPy supports vectorized operations, meaning that operations on entire arrays are implemented in compiled C code, avoiding the need for Python loops and improving performance.\n",
        "\n",
        "- d . Mathematical Functions: NumPy includes a wide array of mathematical functions for linear algebra, Fourier transforms, statistical analysis, and more, making it an essential tool in data science, machine learning, and scientific computing.\n",
        "\n",
        "- e . Interoperability: NumPy arrays are compatible with other scientific libraries like SciPy, Pandas, and Matplotlib, which makes it easy to use in the broader Python ecosystem.\n",
        "\n",
        "- f . Memory Efficiency: NumPy arrays consume less memory than Python lists and allow for the storage of large datasets in an efficient manner.\n",
        "\n",
        "2.  How does broadcasting work in NumPy?\n",
        "- Broadcasting in NumPy is a powerful mechanism that allows operations on arrays of different shapes and sizes without the need for explicit looping or reshaping. It enables element-wise operations by automatically expanding the smaller array to match the shape of the larger array when possible.\n",
        "- How Broadcasting Works\n",
        "When performing operations between two arrays, NumPy compares their shapes element-wise, starting from the trailing dimensions. Two dimensions are considered compatible if:\n",
        "\n",
        "- a . They are equal, or\n",
        "- b . One of them is 1.\n",
        "- If the shapes are compatible, NumPy \"broadcasts\" the smaller array across the larger one so that they have the same shape. The smaller array is virtually duplicated along the dimensions where its size is 1.\n",
        "\n",
        "3 . What is a Pandas DataFrame?\n",
        "- A Pandas DataFrame is a two-dimensional, tabular data structure in Python provided by the Pandas library. It is one of the most widely used data structures for data analysis and manipulation. The DataFrame is highly versatile and resembles a spreadsheet or a SQL table.\n",
        "\n",
        "4. Explain the use of the groupby() method in Pandas.\n",
        "- The groupby() method in Pandas is a powerful tool for grouping and aggregating data within a DataFrame or Series. It is primarily used to split data into groups based on some criteria, apply a function to each group, and combine the results into a new DataFrame or Series.\n",
        "\n",
        "- How groupby() Works\n",
        "- 1 . The groupby() method operates in three steps, often referred to as the split-apply-combine process:\n",
        "\n",
        "- 2 . Split: The data is split into groups based on one or more keys (e.g., column values).\n",
        "- 3 . Apply: A function is applied to each group (e.g., aggregate functions like mean(), sum(), count(), or custom functions).\n",
        "Combine: The results are combined into a new DataFrame or Series.\n",
        "\n",
        "5. Why is Seaborn preferred for statistical visualizations?\n",
        "- 1. Built-in Statistical Functions\n",
        "Seaborn includes many functions designed for visualizing statistical relationships and distributions:\n",
        "\n",
        "- Functions like relplot(), pairplot(), and lmplot() automatically compute and display statistical relationships between variables.\n",
        "- Tools  for visualizing distributions (histplot(), kdeplot(), violinplot(), etc.) allow for detailed statistical insights.\n",
        "- 2. Elegant Default Styles\n",
        "- Seaborn comes with aesthetically pleasing default styles, making visualizations more attractive and publication-ready.\n",
        "- Styles such as whitegrid, darkgrid, and ticks enhance readability and reduce the need for extensive customization.\n",
        "- 3. Ease of Use\n",
        "- Seaborn simplifies complex visualizations with concise syntax. For example, a violin plot or box plot can be created with just one line of code.\n",
        "- Built-in integration with Pandas DataFrames allows for direct use of column names, eliminating the need for manual data extraction.\n",
        "- 4. Works Well with DataFrames\n",
        "- Seaborn seamlessly integrates with Pandas DataFrames, allowing for easy plotting directly from tabular data.\n",
        "- It supports grouping, subsetting, and faceting data for multi-dimensional visualizations.\n",
        "\n",
        "6. What are the differences between NumPy arrays and Python lists?\n",
        "- 1. Data Type Consistency\n",
        "- a . NumPy Arrays:\n",
        "- Require all elements to be of the same data type (e.g., all integers, floats, etc.).\n",
        "- Enforce type uniformity, making them more memory-efficient.\n",
        "-- b . Python Lists:\n",
        "Can store elements of mixed data types (e.g., integers, strings, objects).\n",
        "- 2. Performance\n",
        "- a . NumPy Arrays:\n",
        "- Much faster for numerical computations due to optimized C implementations under the hood.\n",
        "- Allow for vectorized operations (element-wise operations without explicit loops).\n",
        "- b .  Python Lists:\n",
        "- Slower for numerical computations since they rely on Python loops for operations.\n",
        "- No built-in support for vectorized operations.\n",
        "- 3. Memory Efficiency\n",
        "- a . NumPy Arrays:\n",
        "- More memory-efficient because elements are stored in a contiguous block of memory, using a fixed-size data type.\n",
        "- Ideal for handling large datasets.\n",
        "- b . Python Lists:\n",
        "- Less memory-efficient as they store pointers to individual elements, and each element can be of arbitrary size.\n",
        "- 4. Functionality\n",
        "- a . NumPy Arrays:\n",
        "- Designed specifically for numerical and scientific computing.\n",
        "- Offer built-in support for mathematical operations, linear algebra, random number generation, and more.\n",
        "- b . Python Lists:\n",
        "- General-purpose data structure with no specific focus on numerical computations.\n",
        "- Lack direct support for mathematical operations.\n",
        "\n",
        "7 . What is a heatmap, and when should it be used?\n",
        "- A heatmap is a data visualization technique that represents numerical data as a matrix of color-coded cells. Each cell in the grid corresponds to a data point, and its color intensity reflects the magnitude or value of that point. Heatmaps are widely used to visualize patterns, correlations, or distributions in datasets, particularly when working with large amounts of data.\n",
        "- When to Use a Heatmap:\n",
        "- a . Visualizing Correlations:\n",
        "- Heatmaps are often used to display correlation matrices in statistical and machine learning workflows.\n",
        "- Example: Understanding relationships between features in a dataset.\n",
        "- b . Spotting Patterns:\n",
        "- Use heatmaps to identify patterns, trends, or clusters within data.\n",
        "- Example: In time-series data, heatmaps can show changes over time.\n",
        "- c . Highlighting Outliers:\n",
        "- Heatmaps can highlight anomalies or outliers in data due to their distinct colors.\n",
        "- d . Summarizing Multi-dimensional Data:\n",
        "- For datasets with two categorical dimensions, a heatmap can summarize the relationships or frequencies.\n",
        "- e . Performance or Activity Visualization:\n",
        "- Example: Visualizing website traffic, server performance metrics, or customer behavior.\n",
        "- f . Genomics and Bioinformatics:\n",
        "- Widely used in bioinformatics to visualize gene expression data or protein interactions.\n",
        "\n",
        "8 . What does the term “vectorized operation” mean in NumPy?\n",
        "- A vectorized operation in NumPy refers to performing operations on entire arrays (or collections of elements) in a single step, rather than iterating through the elements individually in a loop. These operations are optimized for performance and leverage low-level, highly efficient implementations in C, enabling faster execution compared to traditional Python loops.\n",
        "\n",
        "9. How does Matplotlib differ from Plotly?\n",
        "- 1. Interactivity\n",
        "- Matplotlib:\n",
        "- Primarily a static plotting library. Plots are typically non-interactive and rendered as static images (e.g., PNG, PDF).\n",
        "- Limited interactivity via tools like Matplotlib’s mpl_toolkits or by embedding in GUIs.\n",
        "- Suitable for creating publication-quality plots.\n",
        "- Plotly:\n",
        "- Built for interactive visualizations. Users can zoom, pan, hover for details, and more.\n",
        "- Plots are rendered in web browsers or as interactive components in Jupyter Notebooks.\n",
        "- Ideal for dashboards and presentations requiring dynamic user engagement.\n",
        "- 2. Ease of Use\n",
        "- Matplotlib:\n",
        "- Offers a lot of control but can be verbose and complex for beginners.\n",
        "- Requires more lines of code to create and customize visualizations.\n",
        "- Plotly:\n",
        "- Has a user-friendly API for creating complex and interactive plots with minimal code.\n",
        "- Default settings often produce polished and visually appealing charts.\n",
        "- 3. Output Formats\n",
        "- Matplotlib:\n",
        "- Outputs static files like PNG, PDF, SVG, and more.\n",
        "- Can embed plots into desktop applications using frameworks like PyQt or Tkinter.\n",
        "- Plotly:\n",
        "- Outputs interactive HTML files that can be viewed in browsers or embedded in web applications.\n",
        "- Can also generate static images (requires additional setup or libraries like kaleido).\n",
        "\n",
        "10 . What is the significance of hierarchical indexing in Pandas?\n",
        "- Hierarchical Indexing in Pandas\n",
        "- Hierarchical indexing, also known as a MultiIndex, is a powerful feature in Pandas that allows you to have multiple levels of indexing for rows and/or columns in a DataFrame or Series. This enables you to work with high-dimensional data in a lower-dimensional form and facilitates advanced data manipulation, aggregation, and visualization.\n",
        "\n",
        "11. What is the role of Seaborn’s pairplot() function?\n",
        "- Seaborn’s pairplot() Function\n",
        "- The pairplot() function in Seaborn is a powerful tool for visualizing pairwise relationships in a dataset. It creates a grid of plots where each numeric variable is plotted against every other numeric variable in the dataset. This function is particularly useful for exploratory data analysis (EDA) to understand the relationships between variables and their distributions.\n",
        "\n",
        "12.What is the purpose of the describe() function in Pandas?\n",
        "- The describe() function in Pandas provides a summary statistics of the numerical columns in a DataFrame or Series, allowing you to quickly gain insights into the distribution and central tendencies of your data. It is a commonly used function during the exploratory data analysis (EDA) phase to understand the basic characteristics of the data, such as the mean, median, spread, and presence of outliers.\n",
        "\n",
        "13 . Why is handling missing data important in Pandas?\n",
        "- 1. Impact on Analysis and Models\n",
        "- Distorted Results: Many analytical methods (e.g., mean, median, regression, machine learning algorithms) rely on complete datasets. If missing values are not handled, they can distort statistical summaries and lead to misleading conclusions.\n",
        "- Inconsistent Results: If missing data is not treated consistently, it can lead to biased or inconsistent results, especially when working with predictive models.\n",
        "- Errors in Algorithms: Many machine learning algorithms (e.g., decision trees, linear regression, neural networks) do not handle missing values directly, and attempting to run these algorithms without handling NaN values may result in errors.\n",
        "- 2. Types of Missing Data\n",
        "- Understanding the type of missing data is essential for deciding how to handle it:\n",
        "- Missing Completely at Random (MCAR): The missing values are independent of both observed and unobserved data. In this case, the missing data does not bias the analysis and can be safely removed.\n",
        "- Missing at Random (MAR): The missing data depends on the observed data but not on the unobserved data. In such cases, imputing the missing data based on other available information is a reasonable option.\n",
        "- Missing Not at Random (MNAR): The missing data depends on the unobserved data itself. This is the most challenging case to handle, and advanced techniques such as modeling or domain-specific methods might be needed.\n",
        "\n",
        "14 . What are the benefits of using Plotly for data visualization?\n",
        "- 1. Interactivity\n",
        "- Dynamic Visualizations:\n",
        "- Plotly’s visualizations are inherently interactive, allowing users to zoom, pan, hover for details, and filter data directly in the plots.\n",
        "- This interactivity is particularly useful for exploring large datasets and identifying patterns or outliers.\n",
        "- Hover Tooltips:\n",
        "- Provides detailed information about data points when hovering, which enhances interpretability without cluttering the plot.\n",
        "- 2. Wide Range of Plot Types\n",
        "- Comprehensive Plot Library:\n",
        "- Plotly supports over 40 different chart types, including:\n",
        "- Line, bar, scatter, and pie charts.\n",
        "- 3D plots and surface plots.\n",
        "- Choropleth and geographic maps.\n",
        "- Heatmaps and treemaps.\n",
        "- Sankey diagrams and sunburst charts.\n",
        "- 3 . Free and Open Source\n",
        "- The core version of Plotly is free and open source, making it accessible to everyone. Advanced enterprise features are available through the commercial version, but most common use cases are covered in the free edition.\n",
        "\n",
        "15. How does NumPy handle multidimensional arrays?\n",
        "- 1. What Are Multidimensional Arrays in NumPy\n",
        "- A multidimensional array is represented by the numpy.ndarray object. It is a grid of values of the same type, indexed by a tuple of integers.\n",
        "- The number of dimensions (axes) is called the rank of the array.\n",
        "1D Array: A list-like structure (e.g., [1, 2, 3]).\n",
        "2D Array: A matrix-like structure (e.g., [[1, 2], [3, 4]]).\n",
        "3D Array: A tensor-like structure (e.g., [[[1, 2], [3, 4]], [[5, 6], [7, 8]]]).\n",
        "-  Applications of Multidimensional Arrays\n",
        "- Data Representation: Represent tabular data, images, or time-series data.\n",
        "- Linear Algebra: Perform matrix multiplications, eigenvalue calculations, and other operations.\n",
        "- Numerical Simulations: Model scientific phenomena in multiple dimensions (e.g., 3D physics simulations).\n",
        "- Machine Learning: Process inputs like image tensors, datasets, or neural network weights.\n",
        "\n",
        "16 . What is the role of Bokeh in data visualization?\n",
        "- Bokeh is a powerful Python library designed for creating interactive, web-ready visualizations. It is particularly suited for building dynamic and visually appealing plots that can be seamlessly integrated into web applications.\n",
        "\n",
        "17 .  Explain the difference between apply() and map() in Pandas?\n",
        "- 1. Scope\n",
        "- map():\n",
        "- Works only on a Pandas Series.\n",
        "- Cannot be directly applied to DataFrames.\n",
        "- apply():\n",
        "- Works on both Pandas Series and DataFrames.\n",
        "- For DataFrames, it can operate along rows or columns.\n",
        "- 2 . Performance\n",
        "- map():\n",
        "- Optimized for simple element-wise operations on Series and is usually faster than apply().\n",
        "- apply():\n",
        "- Slightly slower because it is more general and works on both Series and DataFrames, often requiring additional processing to determine the axis and shape of the result.\n",
        "- 3 . Output\n",
        "- map():\n",
        "- The output is always a Series with the same index as the input.\n",
        "- apply():\n",
        "- The output can be a Series, DataFrame, or scalar value depending on the applied function and the input dimensions.\n",
        "\n",
        "18. What are some advanced features of NumPy?\n",
        "- 1. Broadcasting\n",
        "- Feature: Allows operations on arrays of different shapes by automatically expanding their dimensions to make the shapes compatible.\n",
        "- Use Case: Simplifies element-wise operations without explicitly reshaping arrays.\n",
        "- 2. Vectorized Operations\n",
        "- Feature: Enables applying operations to entire arrays without explicit loops, leading to faster execution.\n",
        "- Use Case: Perform mathematical computations efficiently.\n",
        "- 3. Memory-Mapped Files\n",
        "- Feature: Allows working with large datasets by mapping files directly into memory, enabling efficient I/O operations without loading the entire file into RAM.\n",
        "- Use Case: Handle datasets larger than the available memory.\n",
        "- 4. Structured Arrays\n",
        "- Feature: Allows defining arrays with heterogeneous data types (e.g., integers, floats, strings).\n",
        "- Use Case: Work with tabular data in a structured format.\n",
        "- 5. Universal Functions (ufuncs)\n",
        "- Feature: Predefined functions in NumPy that operate element-wise on arrays and support broadcasting.\n",
        "- Use Case: Perform element-wise operations like addition, trigonometric functions, and exponentiation.\n",
        "\n",
        "19 . How does Pandas simplify time series analysis?\n",
        "- 1. Time Indexing and Resampling\n",
        "- Time-Based Indexing:\n",
        " - Pandas allows time series data to be indexed using DatetimeIndex, which enables intuitive slicing and selection.\n",
        "- Resampling:\n",
        "- Convert data to different time frequencies (e.g., daily to monthly, hourly to daily) using aggregation or interpolation.\n",
        "- 2. Flexible Time Representations\n",
        "- Datetime Conversion:\n",
        "- Convert strings, integers, or other formats into datetime objects using pd.to_datetime.\n",
        "- Custom Frequencies:\n",
        "- Use flexible time frequencies like:\n",
        "D (daily), H (hourly), T (minutes), B (business days).\n",
        "- 3. Handling Missing Data\n",
        "- Forward and Backward Filling:\n",
        "- Handle missing values specific to time series using forward (ffill) or backward filling (bfill).\n",
        "- Interpolate:\n",
        "- Interpolate missing data using linear or other interpolation methods.\n",
        "\n",
        "20 . What is the role of a pivot table in Pandas?\n",
        "- Role of a Pivot Table\n",
        "- 1. Data Summarization:\n",
        "- Aggregates data based on one or more keys (columns) to generate summaries, such as sums, averages, counts, etc.\n",
        "- Example: Summarizing total sales by region and product category.\n",
        "- 2. Reshaping Data:\n",
        "- Converts a long-format DataFrame into a wide-format, making it easier to analyze and visualize data.\n",
        "- 3. Custom Aggregations:\n",
        "- Allows applying specific aggregation functions (e.g., sum, mean, min, max, or custom functions) to groups of data.\n",
        "- 4 . Multi-Dimensional Analysis:\n",
        "- Facilitates multi-level grouping and analysis using hierarchical indexes for rows and columns.\n",
        "-5 . Quick Data Insights:\n",
        "- Provides an intuitive way to slice and dice data for exploratory data analysis (EDA).\n",
        "\n",
        "21. Why is NumPy’s array slicing faster than Python’s list slicing?\n",
        "- NumPy’s array slicing is faster than Python’s list slicing primarily due to the differences in how the two handle memory and operations. Here's a detailed explanation of why this is the case:\n",
        "\n",
        "1. Memory Contiguity\n",
        "- NumPy Arrays:\n",
        "- NumPy arrays store data in a single contiguous block of memory (C-style or Fortran-style).\n",
        "- When slicing a NumPy array, it creates a view of the same memory block rather than copying the data.\n",
        "- This allows for constant-time access to the data because the slice refers to the same underlying memory.\n",
        "- Python Lists:\n",
        "- Python lists are collections of pointers to objects, which may be scattered in memory.\n",
        "- Slicing a Python list creates a new list and copies the elements from the original list into the new one, leading to additional overhead in terms of memory allocation and data copying.\n",
        "- 2. Low-Level Optimization\n",
        "- NumPy:\n",
        "- Written in C, NumPy uses highly optimized C functions for slicing and other array operations.\n",
        "- These operations leverage vectorized computations and avoid Python's interpreter overhead.\n",
        "- Slicing in NumPy is implemented using pointer arithmetic to calculate offsets, making it extremely fast.\n",
        "- Python Lists:\n",
        "- Python lists are general-purpose and not optimized for numerical operations.\n",
        "- Each element access involves dereferencing a pointer and may involve type checking and other overhead, slowing down slicing operations.\n",
        "\n",
        "22 . What are some common use cases for Seaborn?\n",
        "- 1. Exploratory Data Analysis (EDA)\n",
        "- Seaborn helps in visually exploring data to identify patterns, trends, correlations, and potential outliers.\n",
        "- 2. Relationship Analysis\n",
        "- Seaborn excels at visualizing relationships between variables.\n",
        "- Scatter Plots:\n",
        "- Explore relationships between two continuous variables.\n",
        "- Regression Plots:\n",
        "- Examine linear relationships with optional confidence intervals.\n",
        "- Pairwise Relationships:\n",
        "- Use pairplot() to visualize relationships across all numerical variables.\n",
        "- 3. Use with Large Datasets\n",
        "- Seaborn's efficient handling of large datasets makes it suitable for analyzing extensive data by creating aggregated visualizations.\n",
        "\n"
      ],
      "metadata": {
        "id": "PiM9O1ebV5DF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "1.  How do you create a 2D NumPy array and calculate the sum of each row?\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create a 2D NumPy array\n",
        "array_2d = np.array([[1, 2, 3],\n",
        "                     [4, 5, 6],\n",
        "                     [7, 8, 9]])\n",
        "\n",
        "print(\"2D Array:\")\n",
        "print(array_2d)\n",
        "\n",
        "# Step 2: Calculate the sum of each row\n",
        "row_sums = np.sum(array_2d, axis=1)\n",
        "print(\"\\nSum of each row:\")\n",
        "print(row_sums)\n",
        "Output\n",
        "2D Array:\n",
        "[[1 2 3]\n",
        " [4 5 6]\n",
        " [7 8 9]]\n",
        "\n",
        "Sum of each row:\n",
        "[ 6 15 24]\n",
        "'''"
      ],
      "metadata": {
        "id": "w2UOkLTiOesx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "2. Write a Pandas script to find the mean of a specific column in a DataFrame?\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Create a sample DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [24, 27, 22, 32, 29],\n",
        "    'Salary': [50000, 60000, 45000, 80000, 70000]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Specify the column for which to calculate the mean\n",
        "column_name = 'Age'\n",
        "\n",
        "# Calculate the mean of the specified column\n",
        "mean_value = df[column_name].mean()\n",
        "\n",
        "print(f\"The mean of the '{column_name}' column is: {mean_value}\")\n",
        "Output\n",
        "The mean of the 'Age' column is: 26.8\n",
        "'''"
      ],
      "metadata": {
        "id": "WoL9NidMPNqr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "3. A Create a scatter plot using Matplotlib.\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Sample data for the scatter plot\n",
        "x = [5, 7, 8, 7, 2, 17, 2, 9, 4, 11]\n",
        "y = [99, 86, 87, 88, 100, 86, 103, 87, 94, 78]\n",
        "\n",
        "# Create the scatter plot\n",
        "plt.scatter(x, y, color='blue', marker='o')\n",
        "\n",
        "# Add labels and title\n",
        "plt.title(\"Sample Scatter Plot\")\n",
        "plt.xlabel(\"X-axis Label\")\n",
        "plt.ylabel(\"Y-axis Label\")\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "Output\n",
        "This code generates a scatter plot with the given x and y data points.\n",
        "'''\n"
      ],
      "metadata": {
        "id": "IzKMaAA2PmwD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "4.  How do you calculate the correlation matrix using Seaborn and visualize it with a heatmap?\n",
        "'''\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create a sample dataset\n",
        "data = {\n",
        "    'Age': [25, 30, 35, 40, 45],\n",
        "    'Salary': [40000, 50000, 60000, 80000, 90000],\n",
        "    'Experience': [1, 3, 5, 8, 10]\n",
        "}\n",
        "\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Calculate the correlation matrix\n",
        "correlation_matrix = df.corr()\n",
        "\n",
        "# Step 3: Visualize with a heatmap\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\", linewidths=0.5)\n",
        "plt.title(\"Correlation Matrix Heatmap\")\n",
        "plt.show()\n",
        "Output\n",
        "he correlation values between variables are displayed in each cell.\n",
        "Colors represent the strength and direction of correlations:\n",
        "Dark Red: Strong positive correlation (close to +1).\n",
        "Dark Blue: Strong negative correlation (close to -1).\n",
        "White or Neutral: Weak or no correlation (close to 0).\n",
        "'''"
      ],
      "metadata": {
        "id": "Wl7XAK3XQNj0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "5. Generate a bar plot using Plotly.\n",
        "'''\n",
        "import plotly.express as px\n",
        "\n",
        "# Sample data for the bar plot\n",
        "data = {\n",
        "    'Category': ['A', 'B', 'C', 'D', 'E'],\n",
        "    'Values': [20, 34, 23, 45, 12]\n",
        "}\n",
        "\n",
        "# Create the bar plot\n",
        "fig = px.bar(data, x='Category', y='Values', title='Bar Plot Example',\n",
        "             labels={'Values': 'Value Count', 'Category': 'Category Name'},\n",
        "             color='Category')  # Optional: Adds color by category\n",
        "\n",
        "# Display the plot\n",
        "fig.show()\n",
        "Output\n",
        "Categories (A, B, C, D, E) on the x-axis.\n",
        "Their respective values on the y-axis as vertical bars.\n",
        "Interactive tooltips for each bar.\n",
        "'''"
      ],
      "metadata": {
        "id": "7617eT-8SeqM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "6. Create a DataFrame and add a new column based on an existing column.\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [25, 30, 35, 40, 22]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Add a new column based on an existing column\n",
        "# Example: Categorize Age into 'Young' or 'Old'\n",
        "df['Age Category'] = df['Age'].apply(lambda age: 'Young' if age < 30 else 'Old')\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(df)\n",
        "Output\n",
        "      Name  Age Age Category\n",
        "0    Alice   25        Young\n",
        "1      Bob   30         Old\n",
        "2  Charlie   35         Old\n",
        "3    David   40         Old\n",
        "4      Eve   22        Young\n",
        "'''"
      ],
      "metadata": {
        "id": "D6NSmcMTS9ke"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "7. Write a program to perform element-wise multiplication of two NumPy arrays.\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create two NumPy arrays\n",
        "array1 = np.array([1, 2, 3, 4, 5])\n",
        "array2 = np.array([10, 20, 30, 40, 50])\n",
        "\n",
        "# Step 2: Perform element-wise multiplication\n",
        "result = array1 * array2\n",
        "\n",
        "# Display the result\n",
        "print(\"Array 1:\", array1)\n",
        "print(\"Array 2:\", array2)\n",
        "print(\"Element-wise Multiplication:\", result)\n",
        "Output\n",
        "Array 1: [1 2 3 4 5]\n",
        "Array 2: [10 20 30 40 50]\n",
        "Element-wise Multiplication: [ 10  40  90 160 250]\n",
        "'''"
      ],
      "metadata": {
        "id": "x_GLfR5CTdEl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "8. A Create a line plot with multiple lines using Matplotlib.\n",
        "'''\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create data for multiple lines\n",
        "x = [1, 2, 3, 4, 5]\n",
        "y1 = [2, 4, 6, 8, 10]  # Line 1\n",
        "y2 = [1, 3, 5, 7, 9]   # Line 2\n",
        "y3 = [3, 6, 9, 12, 15] # Line 3\n",
        "\n",
        "# Step 2: Plot multiple lines\n",
        "plt.plot(x, y1, label='Line 1', color='red', linestyle='-', marker='o')\n",
        "plt.plot(x, y2, label='Line 2', color='blue', linestyle='--', marker='s')\n",
        "plt.plot(x, y3, label='Line 3', color='green', linestyle='-.', marker='d')\n",
        "\n",
        "# Step 3: Add title, labels, and legend\n",
        "plt.title(\"Line Plot with Multiple Lines\")\n",
        "plt.xlabel(\"X-axis Label\")\n",
        "plt.ylabel(\"Y-axis Label\")\n",
        "plt.legend()  # Display legend\n",
        "\n",
        "# Step 4: Show the plot\n",
        "plt.grid(True)  # Optional: Adds a grid for better readability\n",
        "plt.show()\n",
        "Output\n",
        "The plot will display three lines:\n",
        "\n",
        "Line 1: Red solid line with circle markers.\n",
        "Line 2: Blue dashed line with square markers.\n",
        "Line 3: Green dash-dot line with diamond markers.\n",
        "Each line is labeled in the legend for clarity.\n",
        "'''\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "vW6drDGdUD8t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "9. A Generate a Pandas DataFrame and filter rows where a column value is greater than a threshold.\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a DataFrame\n",
        "data = {\n",
        "    'Name': ['Alice', 'Bob', 'Charlie', 'David', 'Eve'],\n",
        "    'Age': [24, 29, 35, 42, 18],\n",
        "    'Score': [85, 90, 88, 75, 95]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Define a threshold\n",
        "threshold = 30\n",
        "\n",
        "# Step 3: Filter rows where 'Age' is greater than the threshold\n",
        "filtered_df = df[df['Age'] > threshold]\n",
        "\n",
        "# Display the original and filtered DataFrame\n",
        "print(\"Original DataFrame:\")\n",
        "print(df)\n",
        "print(\"\\nFiltered DataFrame (Age > 30):\")\n",
        "print(filtered_df)\n",
        "Output\n",
        "      Name  Age  Score\n",
        "0    Alice   24     85\n",
        "1      Bob   29     90\n",
        "2  Charlie   35     88\n",
        "3    David   42     75\n",
        "4      Eve   18     95\n",
        "Filtered DataFrame (Age > 30):\n",
        "      Name  Age  Score\n",
        "2  Charlie   35     88\n",
        "3    David   42     75\n",
        "'''"
      ],
      "metadata": {
        "id": "jlns34JHU_Yg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "10 . A Create a histogram using Seaborn to visualize a distribution.\n",
        "'''\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Step 1: Create sample data\n",
        "data = [22, 23, 24, 25, 26, 27, 27, 28, 29, 30, 30, 31, 32, 33, 34, 35, 35, 36, 37, 38]\n",
        "\n",
        "# Step 2: Create a Seaborn histogram\n",
        "sns.histplot(data, bins=10, kde=True, color='blue', edgecolor='black')\n",
        "\n",
        "# Step 3: Add titles and labels\n",
        "plt.title(\"Histogram of Sample Data\")\n",
        "plt.xlabel(\"Value\")\n",
        "plt.ylabel(\"Frequency\")\n",
        "\n",
        "# Step 4: Display the plot\n",
        "plt.show()\n",
        "Output\n",
        "The plot will display a histogram with:\n",
        "\n",
        "A distribution of the sample data.\n",
        "A Kernel Density Estimate (KDE) curve that estimates the probability density function of the data.\n",
        "'''"
      ],
      "metadata": {
        "id": "rvCCHCejV0Th"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "11. A Perform matrix multiplication using NumPy.\n",
        "'''\n",
        "import numpy as np\n",
        "\n",
        "# Step 1: Create two matrices\n",
        "matrix1 = np.array([[1, 2], [3, 4], [5, 6]])\n",
        "matrix2 = np.array([[7, 8], [9, 10]])\n",
        "\n",
        "# Step 2: Perform matrix multiplication\n",
        "result = np.matmul(matrix1, matrix2)\n",
        "\n",
        "# Display the result\n",
        "print(\"Matrix 1:\")\n",
        "print(matrix1)\n",
        "print(\"\\nMatrix 2:\")\n",
        "print(matrix2)\n",
        "print(\"\\nResult of Matrix Multiplication:\")\n",
        "print(result)\n",
        "Output\n",
        "Matrix 1:\n",
        "[[1 2]\n",
        " [3 4]\n",
        " [5 6]]\n",
        "\n",
        "Matrix 2:\n",
        "[[ 7  8]\n",
        " [ 9 10]]\n",
        "\n",
        "Result of Matrix Multiplication:\n",
        "[[25 28]\n",
        " [57 64]\n",
        " [89 100]]\n",
        "'''"
      ],
      "metadata": {
        "id": "n-OLXw3XWav9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "12. Use Pandas to load a CSV file and display its first 5 rows.\n",
        "'''\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Load the CSV file into a DataFrame\n",
        "df = pd.read_csv('path_to_your_file.csv')  # Replace with your file path\n",
        "\n",
        "# Step 2: Display the first 5 rows\n",
        "print(df.head())\n",
        "Output\n",
        "Name, Age, City\n",
        "Alice, 24, New York\n",
        "Bob, 30, San Francisco\n",
        "Charlie, 28, Los Angeles\n",
        "David, 35, Chicago\n",
        "Eve, 22, Boston\n",
        "'''"
      ],
      "metadata": {
        "id": "uj4KJG6rW6E9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "13. Create a 3D scatter plot using Plotly.\n",
        "'''\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "\n",
        "# Step 1: Create a sample DataFrame with 3D coordinates\n",
        "data = {\n",
        "    'X': [1, 2, 3, 4, 5],\n",
        "    'Y': [5, 4, 3, 2, 1],\n",
        "    'Z': [2, 3, 4, 5, 6]\n",
        "}\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Step 2: Create a 3D scatter plot\n",
        "fig = px.scatter_3d(df, x='X', y='Y', z='Z', title=\"3D Scatter Plot\")\n",
        "\n",
        "# Step 3: Show the plot\n",
        "fig.show()\n",
        "Output\n",
        "A 3D scatter plot will be displayed where each point is plotted in 3D space based on the X, Y, and Z values.\n",
        "'''"
      ],
      "metadata": {
        "id": "HnwQJA3GXiOW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "h2eZ_Ga2knU0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}